{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7029af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from typing import Any, Tuple, Optional, Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a879535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhchung/continual-uda/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a70b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/hhchung/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5baf7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x)\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = self.dropout2(x1)\n",
    "        output = self.fc2(x1)\n",
    "        # if self.training:\n",
    "        features = x1 # torch.stack([x, x1])\n",
    "        return output, features\n",
    "        # else:\n",
    "        #     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ef7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, angle):\n",
    "        self.angle = angle\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return TF.rotate(x, self.angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6c29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReverseFunction(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx: Any, input: torch.Tensor, coeff: Optional[float] = 1.) -> torch.Tensor:\n",
    "        ctx.coeff = coeff\n",
    "        output = input * 1.0\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx: Any, grad_output: torch.Tensor) -> Tuple[torch.Tensor, Any]:\n",
    "        return grad_output.neg() * ctx.coeff, None\n",
    "\n",
    "\n",
    "class GradientReverseLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GradientReverseLayer, self).__init__()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return GradientReverseFunction.apply(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82b302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianKernel(nn.Module):\n",
    "    r\"\"\"Gaussian Kernel Matrix\n",
    "    Gaussian Kernel k is defined by\n",
    "    .. math::\n",
    "        k(x_1, x_2) = \\exp \\left( - \\dfrac{\\| x_1 - x_2 \\|^2}{2\\sigma^2} \\right)\n",
    "    where :math:`x_1, x_2 \\in R^d` are 1-d tensors.\n",
    "    Gaussian Kernel Matrix K is defined on input group :math:`X=(x_1, x_2, ..., x_m),`\n",
    "    .. math::\n",
    "        K(X)_{i,j} = k(x_i, x_j)\n",
    "    Also by default, during training this layer keeps running estimates of the\n",
    "    mean of L2 distances, which are then used to set hyperparameter  :math:`\\sigma`.\n",
    "    Mathematically, the estimation is :math:`\\sigma^2 = \\dfrac{\\alpha}{n^2}\\sum_{i,j} \\| x_i - x_j \\|^2`.\n",
    "    If :attr:`track_running_stats` is set to ``False``, this layer then does not\n",
    "    keep running estimates, and use a fixed :math:`\\sigma` instead.\n",
    "    Args:\n",
    "        sigma (float, optional): bandwidth :math:`\\sigma`. Default: None\n",
    "        track_running_stats (bool, optional): If ``True``, this module tracks the running mean of :math:`\\sigma^2`.\n",
    "          Otherwise, it won't track such statistics and always uses fix :math:`\\sigma^2`. Default: ``True``\n",
    "        alpha (float, optional): :math:`\\alpha` which decides the magnitude of :math:`\\sigma^2` when track_running_stats is set to ``True``\n",
    "    Inputs:\n",
    "        - X (tensor): input group :math:`X`\n",
    "    Shape:\n",
    "        - Inputs: :math:`(minibatch, F)` where F means the dimension of input features.\n",
    "        - Outputs: :math:`(minibatch, minibatch)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma: Optional[float] = None, track_running_stats: Optional[bool] = True,\n",
    "                 alpha: Optional[float] = 1.):\n",
    "        super(GaussianKernel, self).__init__()\n",
    "        assert track_running_stats or sigma is not None\n",
    "        self.sigma_square = torch.tensor(sigma * sigma) if sigma is not None else None\n",
    "        self.track_running_stats = track_running_stats\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        l2_distance_square = ((X.unsqueeze(0) - X.unsqueeze(1)) ** 2).sum(2)\n",
    "\n",
    "        if self.track_running_stats:\n",
    "            self.sigma_square = self.alpha * torch.mean(l2_distance_square.detach())\n",
    "\n",
    "        return torch.exp(-l2_distance_square / (2 * self.sigma_square))\n",
    "    \n",
    "class JointMultipleKernelMaximumMeanDiscrepancy(nn.Module):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        kernels (tuple(tuple(torch.nn.Module))): kernel functions, where `kernels[r]` corresponds to kernel :math:`k^{\\mathcal{L}[r]}`.\n",
    "        linear (bool): whether use the linear version of JAN. Default: False\n",
    "        thetas (list(Theta): use adversarial version JAN if not None. Default: None\n",
    "    Inputs:\n",
    "        - z_s (tuple(tensor)): multiple layers' activations from the source domain, :math:`z^s`\n",
    "        - z_t (tuple(tensor)): multiple layers' activations from the target domain, :math:`z^t`\n",
    "    Shape:\n",
    "        - :math:`z^{sl}` and :math:`z^{tl}`: :math:`(minibatch, *)`  where * means any dimension\n",
    "        - Outputs: scalar\n",
    "    .. note::\n",
    "        Activations :math:`z^{sl}` and :math:`z^{tl}` must have the same shape.\n",
    "    .. note::\n",
    "        The kernel values will add up when there are multiple kernels for a certain layer.\n",
    "    Examples::\n",
    "        >>> feature_dim = 1024\n",
    "        >>> batch_size = 10\n",
    "        >>> layer1_kernels = (GaussianKernel(alpha=0.5), GaussianKernel(1.), GaussianKernel(2.))\n",
    "        >>> layer2_kernels = (GaussianKernel(1.), )\n",
    "        >>> loss = JointMultipleKernelMaximumMeanDiscrepancy((layer1_kernels, layer2_kernels))\n",
    "        >>> # layer1 features from source domain and target domain\n",
    "        >>> z1_s, z1_t = torch.randn(batch_size, feature_dim), torch.randn(batch_size, feature_dim)\n",
    "        >>> # layer2 features from source domain and target domain\n",
    "        >>> z2_s, z2_t = torch.randn(batch_size, feature_dim), torch.randn(batch_size, feature_dim)\n",
    "        >>> output = loss((z1_s, z2_s), (z1_t, z2_t))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernels: Sequence[Sequence[nn.Module]], linear: Optional[bool] = True, thetas: Sequence[nn.Module] = None):\n",
    "        super(JointMultipleKernelMaximumMeanDiscrepancy, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.index_matrix = None\n",
    "        self.linear = linear\n",
    "        if thetas:\n",
    "            self.thetas = thetas\n",
    "        else:\n",
    "            self.thetas = [nn.Identity() for _ in kernels]\n",
    "\n",
    "    def forward(self, z_s: torch.Tensor, z_t: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = int(z_s[0].size(0))\n",
    "        self.index_matrix = _update_index_matrix(batch_size, self.index_matrix, self.linear).to(z_s[0].device)\n",
    "\n",
    "        kernel_matrix = torch.ones_like(self.index_matrix)\n",
    "        for layer_z_s, layer_z_t, layer_kernels, theta in zip(z_s, z_t, self.kernels, self.thetas):\n",
    "            layer_features = torch.cat([layer_z_s, layer_z_t], dim=0)\n",
    "            layer_features = theta(layer_features)\n",
    "            kernel_matrix *= sum(\n",
    "                [kernel(layer_features) for kernel in layer_kernels])  # Add up the matrix of each kernel\n",
    "\n",
    "        # Add 2 / (n-1) to make up for the value on the diagonal\n",
    "        # to ensure loss is positive in the non-linear version\n",
    "        loss = (kernel_matrix * self.index_matrix).sum() + 2. / float(batch_size - 1)\n",
    "        return loss\n",
    "\n",
    "def _update_index_matrix(batch_size: int, index_matrix: Optional[torch.Tensor] = None,\n",
    "                         linear: Optional[bool] = True) -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    Update the `index_matrix` which convert `kernel_matrix` to loss.\n",
    "    If `index_matrix` is a tensor with shape (2 x batch_size, 2 x batch_size), then return `index_matrix`.\n",
    "    Else return a new tensor with shape (2 x batch_size, 2 x batch_size).\n",
    "    \"\"\"\n",
    "    if index_matrix is None or index_matrix.size(0) != batch_size * 2:\n",
    "        index_matrix = torch.zeros(2 * batch_size, 2 * batch_size)\n",
    "        if linear:\n",
    "            for i in range(batch_size):\n",
    "                s1, s2 = i, (i + 1) % batch_size\n",
    "                t1, t2 = s1 + batch_size, s2 + batch_size\n",
    "                index_matrix[s1, s2] = 1. / float(batch_size)\n",
    "                index_matrix[t1, t2] = 1. / float(batch_size)\n",
    "                index_matrix[s1, t2] = -1. / float(batch_size)\n",
    "                index_matrix[s2, t1] = -1. / float(batch_size)\n",
    "        else:\n",
    "            for i in range(batch_size):\n",
    "                for j in range(batch_size):\n",
    "                    if i != j:\n",
    "                        index_matrix[i][j] = 1. / float(batch_size * (batch_size - 1))\n",
    "                        index_matrix[i + batch_size][j + batch_size] = 1. / float(batch_size * (batch_size - 1))\n",
    "            for i in range(batch_size):\n",
    "                for j in range(batch_size):\n",
    "                    index_matrix[i][j + batch_size] = -1. / float(batch_size * batch_size)\n",
    "                    index_matrix[i + batch_size][j] = -1. / float(batch_size * batch_size)\n",
    "    return index_matrix\n",
    "    \n",
    "class Theta(nn.Module):\n",
    "    \"\"\"\n",
    "    maximize loss respect to :math:`\\theta`\n",
    "    minimize loss respect to features\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int):\n",
    "        super(Theta, self).__init__()\n",
    "        self.grl1 = GradientReverseLayer()\n",
    "        self.grl2 = GradientReverseLayer()\n",
    "        self.layer1 = nn.Linear(dim, dim)\n",
    "        nn.init.eye_(self.layer1.weight)\n",
    "        nn.init.zeros_(self.layer1.bias)\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.grl1(features)\n",
    "        return self.grl2(self.layer1(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d1d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, classifier, device, train_loader, optimizer):\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    total_size = 0\n",
    "    for data, target in tqdm(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = classifier(encoder(data))\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_size = data.shape[0]\n",
    "        total_train_loss += loss.item() * batch_size\n",
    "        total_size += batch_size\n",
    "    \n",
    "    total_train_loss /= total_size\n",
    "    return total_train_loss\n",
    "\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def test(encoder, classifier, device, test_loader):\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    total_test_loss = 0  \n",
    "    total_correct = 0\n",
    "    total_size = 0\n",
    "    \n",
    "    \n",
    "    for data, target in tqdm(test_loader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = classifier(encoder(data))\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=1), target, reduction='sum')\n",
    "        total_test_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        total_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total_size += data.shape[0]\n",
    "    \n",
    "    total_test_loss /= total_size\n",
    "    total_correct /= total_size\n",
    "    \n",
    "    return total_test_loss, total_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c36d92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt(encoder, classifier, jmmd_loss, device, src_loader, tgt_loader, optimizer, e, epochs, lambda_coeff):\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "    jmmd_loss.train()\n",
    "    len_dataloader = min(len(src_loader), len(tgt_loader))\n",
    "    src_iter = iter(src_loader)\n",
    "    tgt_iter = iter(tgt_loader)\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_cls_loss = 0\n",
    "    total_transfer_loss = 0\n",
    "    total_src_data_size = 0\n",
    "    \n",
    "    for i in tqdm(range(len_dataloader)):\n",
    "        src_data, src_label = src_iter.next()\n",
    "        src_data, src_label = src_data.to(device), src_label.to(device)\n",
    "        \n",
    "        tgt_data, _ = tgt_iter.next()\n",
    "        tgt_data = tgt_data.to(device)\n",
    "        \n",
    "        src_y, src_f = classifier(encoder(src_data))\n",
    "        tgt_y, tgt_f = classifier(encoder(tgt_data))\n",
    "        cls_loss = F.nll_loss(F.log_softmax(src_y, dim=1), src_label)\n",
    "        transfer_loss = jmmd_loss((src_f, F.softmax(src_y, dim=1)), (tgt_f, F.softmax(tgt_y, dim=1)))\n",
    "        loss = cls_loss + transfer_loss * lambda_coeff\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * src_data.size(0)\n",
    "        total_cls_loss += cls_loss.item() * src_data.size(0)\n",
    "        total_transfer_loss += transfer_loss.item() * src_data.size(0)\n",
    "        total_src_data_size += src_data.size(0)\n",
    "    \n",
    "    total_loss /= total_src_data_size\n",
    "    total_cls_loss /= total_src_data_size\n",
    "    total_transfer_loss /= total_src_data_size\n",
    "    return total_loss, total_cls_loss, total_transfer_loss\n",
    "    \n",
    "@torch.no_grad()\n",
    "def adapt_test(encoder, classifier, jmmd_loss, device, src_loader, tgt_loader, e, epochs, lambda_coeff):\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    jmmd_loss.eval()\n",
    "    len_dataloader = min(len(src_loader), len(tgt_loader))\n",
    "    src_iter = iter(src_loader)\n",
    "    tgt_iter = iter(tgt_loader)\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_cls_loss = 0\n",
    "    total_transfer_loss = 0\n",
    "    total_src_data_size = 0\n",
    "    \n",
    "    for i in tqdm(range(len_dataloader)):\n",
    "        src_data, src_label = src_iter.next()\n",
    "        src_data, src_label = src_data.to(device), src_label.to(device)\n",
    "        \n",
    "        tgt_data, _ = tgt_iter.next()\n",
    "        tgt_data = tgt_data.to(device)\n",
    "        \n",
    "        src_y, src_f = classifier(encoder(src_data))\n",
    "        tgt_y, tgt_f = classifier(encoder(tgt_data))\n",
    "        cls_loss = F.nll_loss(F.log_softmax(src_y, dim=1), src_label)\n",
    "        transfer_loss = jmmd_loss((src_f, F.softmax(src_y, dim=1)), (tgt_f, F.softmax(tgt_y, dim=1)))\n",
    "        loss = cls_loss + transfer_loss * lambda_coeff\n",
    "        \n",
    "        \n",
    "        total_loss += loss.item() * src_data.size(0)\n",
    "        total_cls_loss += cls_loss.item() * src_data.size(0)\n",
    "        total_transfer_loss += transfer_loss.item() * src_data.size(0)\n",
    "        total_src_data_size += src_data.size(0)\n",
    "    \n",
    "    total_loss /= total_src_data_size\n",
    "    total_cls_loss /= total_src_data_size\n",
    "    total_transfer_loss /= total_src_data_size\n",
    "    return total_loss, total_cls_loss, total_transfer_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cfcdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpuID = 1\n",
    "device = torch.device('cuda:' + str(gpuID) if torch.cuda.is_available() else 'cpu')\n",
    "encoder = Encoder().to(device)\n",
    "classifier = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0ff84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.1307,), (0.3081,))\n",
    "          ])\n",
    "train_dataset = datasets.MNIST(data_root, train=True, download=True,\n",
    "                          transform=transform)\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "test_dataset = datasets.MNIST(data_root, train=False,\n",
    "                       transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "epochs = 5\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ac28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:07<00:00, 55.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 80.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/5 Train Loss: 0.24, Val Loss: 0.066, Val Accuracy: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:05<00:00, 71.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 80.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2/5 Train Loss: 0.089, Val Loss: 0.049, Val Accuracy: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:05<00:00, 71.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 80.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3/5 Train Loss: 0.067, Val Loss: 0.043, Val Accuracy: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:05<00:00, 71.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 80.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4/5 Train Loss: 0.054, Val Loss: 0.052, Val Accuracy: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:05<00:00, 71.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 80.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5/5 Train Loss: 0.048, Val Loss: 0.042, Val Accuracy: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, epochs + 1):\n",
    "    train_loss = train(encoder, classifier, device, train_loader, optimizer)\n",
    "    val_loss, correct = test(encoder, classifier, device, val_loader)\n",
    "    print(f'Epoch:{e}/{epochs} Train Loss: {round(train_loss, 3)}, Val Loss: {round(val_loss, 3)}, Val Accuracy: {round(correct, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd97aac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 80.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029825609946274197 0.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test(encoder, classifier, device, test_loader)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c325d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3677e1f9",
   "metadata": {},
   "source": [
    "## Rotate 30 Degrees ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ce4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.1307,), (0.3081,)),\n",
    "          MyRotationTransform(30)\n",
    "          ])\n",
    "\n",
    "train_dataset_30 = datasets.MNIST(data_root, train=True, download=True,\n",
    "                          transform=transform)\n",
    "train_dataset_30, val_dataset_30 = torch.utils.data.random_split(train_dataset_30, [50000, 10000])\n",
    "test_dataset_30 = datasets.MNIST(data_root, train=False,\n",
    "                       transform=transform)\n",
    "\n",
    "\n",
    "train_loader_30 = torch.utils.data.DataLoader(train_dataset_30, batch_size=128, shuffle=True)\n",
    "val_loader_30 = torch.utils.data.DataLoader(val_dataset_30, batch_size=128, shuffle=True)\n",
    "test_loader_30 = torch.utils.data.DataLoader(test_dataset_30, batch_size=128, shuffle=False)\n",
    "\n",
    "epochs = 100\n",
    "encoder_30 = deepcopy(encoder)\n",
    "classifier_30 = deepcopy(classifier)\n",
    "optimizer_30 = torch.optim.Adam(list(encoder_30.parameters()) + list(classifier_30.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb94e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = None # none adversarial\n",
    "jmmd_loss = JointMultipleKernelMaximumMeanDiscrepancy(\n",
    "    kernels=(\n",
    "        [GaussianKernel(alpha=2 ** k) for k in range(-3, 2)],\n",
    "        (GaussianKernel(sigma=0.92, track_running_stats=False),)\n",
    "    ),\n",
    "    linear=False, thetas=thetas\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad3065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:18<00:00, 20.68it/s]\n",
      "  0%|                                                                                                                                         | 0/391 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      8\u001b[0m     total_train_loss, total_train_cls_loss, total_train_transfer_loss \u001b[38;5;241m=\u001b[39m adapt(encoder, classifier, jmmd_loss, device, train_loader, train_loader_30, optimizer_30, e, epochs, lambda_coeff)\n\u001b[0;32m----> 9\u001b[0m     total_val_loss, total_val_cls_loss, total_val_transfer_loss \u001b[38;5;241m=\u001b[39m \u001b[43madapt_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjmmd_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_30\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_coeff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Total Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_train_loss,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Train Src Cls Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_train_cls_loss,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Train Tgt Transfer Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_train_transfer_loss,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Val Total Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_val_loss,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Val Src Cls Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_val_cls_loss,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Val Tgt Transfer Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_val_transfer_loss,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test(encoder_30, classifier_30, device, test_loader_30)\n",
      "File \u001b[0;32m~/continual-uda/.venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [9], line 62\u001b[0m, in \u001b[0;36madapt_test\u001b[0;34m(encoder, classifier, jmmd_loss, device, src_loader, tgt_loader, e, epochs, lambda_coeff)\u001b[0m\n\u001b[1;32m     59\u001b[0m tgt_data, _ \u001b[38;5;241m=\u001b[39m tgt_iter\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m     60\u001b[0m tgt_data \u001b[38;5;241m=\u001b[39m tgt_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 62\u001b[0m src_y, src_f \u001b[38;5;241m=\u001b[39m classifier(encoder(src_data))\n\u001b[1;32m     63\u001b[0m tgt_y, tgt_f \u001b[38;5;241m=\u001b[39m classifier(encoder(tgt_data))\n\u001b[1;32m     64\u001b[0m cls_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(F\u001b[38;5;241m.\u001b[39mlog_softmax(src_y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), src_label)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# lambda_coef_list = [10, 5, 3, 1]\n",
    "\n",
    "# for lambda_coef in lambda_coef_list:\n",
    "lambda_coeff = 1.0\n",
    "best_val_loss = 0\n",
    "best_encoder_30, best_classifier_30 = None, None\n",
    "for e in range(1, epochs + 1):\n",
    "    total_train_loss, total_train_cls_loss, total_train_transfer_loss = adapt(encoder, classifier, jmmd_loss, device, train_loader, train_loader_30, optimizer_30, e, epochs, lambda_coeff)\n",
    "    total_val_loss, total_val_cls_loss, total_val_transfer_loss = adapt_test(encoder, classifier, jmmd_loss, device, val_loader, val_loader_30, e, epochs, lambda_coeff)\n",
    "\n",
    "    print(f'Train Total Loss: {round(total_train_loss,3)} Train Src Cls Loss: {round(total_train_cls_loss,3)} Train Tgt Transfer Loss: {round(total_train_transfer_loss,3)} \\n Val Total Loss: {round(total_val_loss,3)} Val Src Cls Loss: {round(total_val_cls_loss,3)} Val Tgt Transfer Loss: {round(total_val_transfer_loss,3)}')\n",
    "    test_loss, test_acc = test(encoder_30, classifier_30, device, test_loader_30)\n",
    "    print(f\"Test Loss: {test_loss} Test Acc: {test_acc}\")\n",
    "\n",
    "\n",
    "encoder_30 = deepcopy(best_encoder_30)\n",
    "classifier_30 = deepcopy(best_classifier_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831048b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(encoder_30, classifier_30, device, test_loader_30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
